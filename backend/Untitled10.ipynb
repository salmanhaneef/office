{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30beeba6-14a5-42f2-b993-857a679bab3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Premium DataFrame:\n",
      "           Description   Premium1 Premium2 Premium3  Total Premium\n",
      "0  Premium by Vehicle:  $1,714.00  $967.00  $974.00         3655.0\n",
      "\n",
      "coveragesss DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Policy_data\n",
      "                      Named Insured  \\\n",
      "0  HAMID HASSAN Agent: 877-780-4626   \n",
      "1                              None   \n",
      "\n",
      "                                       Policy Number  \\\n",
      "0  Policy Number: PAA80002189855 Transaction Type...   \n",
      "1                                               None   \n",
      "\n",
      "                                   Effective  \n",
      "0  Policy Effective 06/20/2024 to 06/20/2025  \n",
      "1       Date: 12:01 am Eastern Standard Time  \n",
      "Persons DataFrame:\n",
      "             Name         DOB                  Status\n",
      "0    HAMID HASSAN  02/11/1979  Insured on This Policy\n",
      "1  TANZEELA HAMID  10/22/1983  Insured on This Policy\n",
      "2   KASHIF HASSAN  11/08/2002  Insured on This Policy\n",
      "\n",
      "Vehicles DataFrame:\n",
      "                Description                VIN\n",
      "0  2020 TOYT TUNDRA CREWMAX  5TFDY5F1XLX935688\n",
      "1       2011 TOYT SIENNA LE  5TDKK3DC8BS090409\n",
      "2      2000 ACUR INTEGRA LS  JH4DC4358YS005713\n",
      "\n",
      "Policy DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Policy6 DataFrame:\n",
      "                     Coverage       Premium1       Premium2       Premium3\n",
      "0               Bodily Injury  $25,000/ $351  $25,000/ $340  $25,000/ $340\n",
      "1   each person/each accident        $50,000        $50,000        $50,000\n",
      "2             Property Damage       $100,000           $289       $100,000\n",
      "3               Bodily Injury   $25,000/ $54   $25,000/ $54   $25,000/ $54\n",
      "4   each person/each accident        $50,000        $50,000        $50,000\n",
      "5             Property Damage       $100,000            $56       $100,000\n",
      "6       Medical Expense Limit        $15,000           $189        $15,000\n",
      "7               Comprehensive           $500           $158           None\n",
      "8                   Collision         $1,000           $577           None\n",
      "9   Substitute Transportation    $40/ $1,200            $30           None\n",
      "10         Premium by Vehicle       1,714.00         967.00         974.00\n",
      "\n",
      "Coverages DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Premises DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Data successfully written to insurance_report_combined.xlsx\n"
     ]
    }
   ],
   "source": [
    "###complete code\n",
    "import re  \n",
    "import pdfplumber  \n",
    "from collections import namedtuple  \n",
    "import pandas as pd  \n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Border, Side, Alignment, Font\n",
    "\n",
    "# Define named tuples to hold the extracted data  \n",
    "Person = namedtuple('Person', 'Name DOB Status')  \n",
    "Vehicle = namedtuple('Vehicle', 'Description VIN')\n",
    "CoverageDetails = namedtuple('CoverageDetails', 'Coverage Premium1 Premium2 Premium3')\n",
    "Line = namedtuple('Line', 'Commercial_Package_Policy Premium')\n",
    "Premises = namedtuple('Premises', 'Premises_Number Address Blanket_and_Limit Valuation Coinsurance Inflation_Guard')\n",
    "Coverages = namedtuple('Coverages', 'Coverage LIMITS Notes')\n",
    "Line1 = namedtuple('Line1', 'Coverage_Type Limit Premium')\n",
    "file = '6.pdf'  \n",
    "\n",
    "# Regex patterns\n",
    "premises_address_re = re.compile(r'(\\d{3})\\s+(.*?(?:\\s+PA,\\s+\\d{5}))')\n",
    "premises_details_re = re.compile(r'(\\d{3})\\s+\\$?([\\d,]+)\\s+([\\w\\s-]*)\\s+(\\d+)%\\s+(\\d+)%\\s*([\\w\\s-]*)?')\n",
    "coverage_re = re.compile(  \n",
    "    r'([A-Za-z\\s\\–]+(?:\\n[A-Za-z\\s\\–]+)*)\\s+\\$(\\d{1,3}(?:,\\d{3})*)(?:\\s+\\w+)?'  \n",
    "    r'([A-Za-z\\s]+(?:\\n[A-Za-z\\s]+)*)?$'  # Capture any additional notes or terms  \n",
    ")  \n",
    "\n",
    "pattern68 = re.compile(\n",
    "    r'([A-Za-z\\s\\–/]+)\\s+\\$(\\d{1,3}(?:,\\d{3})*)\\s+per Occurrence\\s+\\$\\s*(\\d{1,3}(?:,\\d{3})*)\\s+per Occurrence'\n",
    ")\n",
    " \n",
    "person_re = re.compile(r'([A-Z\\s]+)\\s+(\\d{2}/\\d{2}/\\d{4})\\s+(Insured on This Policy)')  \n",
    "vehicle_re = re.compile(r'(\\d{4}\\s[A-Z\\s]+\\s[A-Z\\s]+)\\s([0-9A-Z]{17})')\n",
    "amount_re = re.compile(r'([A-Za-z\\s,]+?)(?:\\s+\\$([\\d,]+\\.\\d{2})| Not Covered|:\\s*\\$.00)')  \n",
    "total_re = re.compile(r'Estimated Total Premium:\\s*\\$([\\d,]+\\.\\d{2})')\n",
    "amount_re1 = re.compile(r'([A-Za-z\\s/()]+)\\s+(\\$\\d{1,3}(?:,\\d{3})*(?:/\\s*\\$?\\d{1,3}(?:,\\d{3})*)?)?\\s+(\\$\\d{1,3}(?:,\\d{3})*(?:/\\s*\\$?\\d{1,3}(?:,\\d{3})*)?)?\\s+(\\$\\d{1,3}(?:,\\d{3})*(?:/\\s*\\$?\\d{1,3}(?:,\\d{3})*)?)?(?:\\s+Included)?')  \n",
    "total_re1 = re.compile(r'([A-Za-z\\s,]+?)(?:\\s+\\$([\\d,]+\\.\\d{2})(?:\\s+\\$([\\d,]+\\.\\d{2}))(?:\\s+\\$([\\d,]+\\.\\d{2})))')\n",
    "###\n",
    "pattern = re.compile(r'^(.*?)\\s+\\$(.*?)\\s+(\\d+(?:,\\d+)?(?:\\.\\d+)?)\\s*(\\d+|$)', re.MULTILINE)  \n",
    "vehicle_premium_pattern = re.compile(r\"Total premium for \\d{4} [A-Z]+\\s*[A-Z]*\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\")  \n",
    "total_policy_premium_pattern = re.compile(r\"Total Policy Premium:\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\")  \n",
    "subtotal_policy_premium_pattern = re.compile(r\"Subtotal policy premium\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\")  \n",
    "total_6_month_premium_pattern = re.compile(r\"Total 6 month policy premium and fees\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\") \n",
    "premium_pattern = re.compile(r'Premium by Vehicle\\s+(\\$[\\d,]+\\.\\d{2})\\s+(\\$[\\d,]+\\.\\d{2})\\s+(\\$[\\d,]+\\.\\d{2})')\n",
    "# Initialize lists to hold the extracted data  \n",
    "persons_list = []  \n",
    "vehicles_list = []  \n",
    "lines_list = []\n",
    "lines_list1 = []\n",
    "lines_list2 = []\n",
    "premises_list = []\n",
    "coverages_list = []\n",
    "Named_Insured_Mailing_Address = []  \n",
    "Policy_Number = []  \n",
    "Effective = []\n",
    "premiums = []  \n",
    "found_named_insured = False  \n",
    "found_policy_number = False  \n",
    "found_effective_from = False\n",
    "\n",
    "# Extract text from the PDF  \n",
    "with pdfplumber.open(file) as pdf:  \n",
    "    for page_number, page in enumerate(pdf.pages, start=1):  \n",
    "        text = page.extract_text()  \n",
    "        if text:  \n",
    "            lines = text.split('\\n')\n",
    "            ##\n",
    "            index1 = [i + 1 for i, x in enumerate(lines) if \"LOSS SUSTAINED CRIME COVERAGE PART DECLARATIONS\" in x]\n",
    "            if index1:\n",
    "                coverages_list.append(Coverages(Coverage=\"LOSS SUSTAINED CRIME COVERAGE PART DECLARATIONS\", LIMITS=None, Notes=None))\n",
    "                start_line = index1[0]\n",
    "                for line in lines[start_line:]:\n",
    "                    match3=pattern68.match(line)\n",
    "                    if match3:\n",
    "                        coverages_list.append(Coverages(Coverage=match3.group(1).strip(), LIMITS=f\"${match3.group(2)} per Occurrence\", Notes=None))\n",
    "            \n",
    "            index = [i + 1 for i, x in enumerate(lines) if \"RELIGIOUS ORGANIZATION MANAGEMENT LIABILITY\" in x]\n",
    "            if index:\n",
    "                pre_index =[i + 1 for i, x in enumerate(lines) if \"COVERAGE PART DECLARATIONS\" in x]\n",
    "                start_line = index[0]\n",
    "                if pre_index:\n",
    "                    coverages_list.append(Coverages(Coverage=\"RELIGIOUS ORGANIZATION MANAGEMENT LIABILITY COVERAGE PART DECLARATIONS\", LIMITS=None, Notes=None))\n",
    "                    start_line = index[0]\n",
    "                    for line in lines[start_line:]:\n",
    "                        match = coverage_re.match(line)\n",
    "                        if match:\n",
    "                            coverage_title = match.group(1).strip()\n",
    "                            limits = match.group(2).strip()\n",
    "                            notes = match.group(3).strip() if match.group(3) is not None else \"\"\n",
    "                            coverages_list.append(Coverages(Coverage=coverage_title, LIMITS=limits, Notes=notes))\n",
    "            general_liability_index = [i + 1 for i, x in enumerate(lines) if \"GENERAL LIABILITY COVERAGE PART DECLARATIONS\" in x] \n",
    "            if general_liability_index:\n",
    "                \n",
    "                coverages_list.append(Coverages(Coverage=\"GENERAL LIABILITY COVERAGE PART DECLARATIONS\", LIMITS=None, Notes=None))\n",
    "                start_line = general_liability_index[0]\n",
    "                for line in lines[start_line:]:\n",
    "                    match = coverage_re.match(line)\n",
    "                    if match:\n",
    "                        coverage_title = match.group(1).strip()\n",
    "                        limits = match.group(2).strip()\n",
    "                        notes = match.group(3).strip() if match.group(3) is not None else \"\"\n",
    "                        coverages_list.append(Coverages(Coverage=coverage_title, LIMITS=limits, Notes=notes))\n",
    "            violent_event_index = [i + 1 for i, x in enumerate(lines) if \"VIOLENT EVENT EXPENSE COVERAGE\" in x]\n",
    "            if violent_event_index:\n",
    "                coverages_list.append(Coverages(Coverage=\"VIOLENT EVENT EXPENSE COVERAGE\", LIMITS=None, Notes=None))\n",
    "                start_line = violent_event_index[0]\n",
    "                for line in lines[start_line:]:\n",
    "                    match = coverage_re.match(line)\n",
    "                    if match:\n",
    "                        coverage_title = match.group(1).strip()\n",
    "                        limits = match.group(2).strip()\n",
    "                        notes = match.group(3).strip() if match.group(3) is not None else \"\"\n",
    "                        coverages_list.append(Coverages(Coverage=coverage_title, LIMITS=limits, Notes=notes))\n",
    "            religious_counseling_index = [i + 1 for i, x in enumerate(lines) if \"RELIGIOUS COUNSELING SERVICES LIABILITY\" in x]\n",
    "            if religious_counseling_index:\n",
    "                start_line = religious_counseling_index[0]\n",
    "                religious_counseling_index1 = [i + 1 for i, x in enumerate(lines) if \"COVERAGE\" in x]\n",
    "                if religious_counseling_index1:\n",
    "                    coverages_list.append(Coverages(Coverage=\"RELIGIOUS COUNSELING SERVICES LIABILITY COVERAGE\", LIMITS=None, Notes=None))\n",
    "                    start_line = religious_counseling_index1[0]\n",
    "                    for line in lines[start_line:]:\n",
    "                        match = coverage_re.match(line)\n",
    "                        if match:\n",
    "                            coverage_title = match.group(1).strip()\n",
    "                            limits = match.group(2).strip()\n",
    "                            notes = match.group(3).strip() if match.group(3) is not None else \"\"\n",
    "                            coverages_list.append(Coverages(Coverage=coverage_title, LIMITS=limits, Notes=notes))\n",
    "            index1 = [i + 1 for i, x in enumerate(lines) if \"Primary use of the vehicle: Pleasure/Personal\" in x]\n",
    "            if index1:\n",
    "                start_line = index1[0]\n",
    "                for line in lines[start_line:]:\n",
    "                    match3 = pattern.match(line)  \n",
    "                    vehicle_premium_match = vehicle_premium_pattern.search(line)  \n",
    "                    total_policy_premium_match = total_policy_premium_pattern.search(line)  \n",
    "                    subtotal_policy_premium_match = subtotal_policy_premium_pattern.search(line)  \n",
    "                    total_6_month_premium_match = total_6_month_premium_pattern.search(line)\n",
    "                    # Capture coverage lines  \n",
    "                    if match3:  \n",
    "                        coverage_title = match3.group(1).strip()  \n",
    "                        limits = match3.group(2).strip()  \n",
    "                        notes = match3.group(3).strip() if match3.group(3) is not None else \"\"  \n",
    "                        lines_list2.append(Line1(Coverage_Type=coverage_title, Limit=limits, Premium=notes))  \n",
    "\n",
    "                    # Check for vehicle premium match and handle accordingly  \n",
    "                    if vehicle_premium_match:  \n",
    "                        coverage_title = \"Vehicle Premium\"   \n",
    "                        limits = None  \n",
    "                        notes = vehicle_premium_match.group(1).strip() if vehicle_premium_match else \"\"  \n",
    "                        lines_list2.append(Line1(Coverage_Type=coverage_title, Limit=limits, Premium=notes))  \n",
    "                    \n",
    "                    # Capture total policy premium  \n",
    "                    # Capture subtotal policy premium  \n",
    "                    if subtotal_policy_premium_match:  \n",
    "                        coverage_title = \"Subtotal Policy Premium\"   \n",
    "                        limits = None  \n",
    "                        notes = subtotal_policy_premium_match.group(1).strip() if subtotal_policy_premium_match else \"\"  \n",
    "                        lines_list2.append(Line1(Coverage_Type=coverage_title, Limit=limits, Premium=notes))  \n",
    "\n",
    "                    # Capture total 6 month premium  \n",
    "                    if total_6_month_premium_match:  \n",
    "                        coverage_title = \"Total 6 Month Premium\"   \n",
    "                        limits = None  \n",
    "                        notes = total_6_month_premium_match.group(1).strip() if total_6_month_premium_match else \"\"  \n",
    "                        lines_list2.append(Line1(Coverage_Type=coverage_title, Limit=limits, Premium=notes))\n",
    "                    \n",
    "            for line in lines:\n",
    "                match_address = premises_address_re.search(line)\n",
    "                if match_address:\n",
    "                    premises_number = match_address.group(1).strip()\n",
    "                    premises_address = match_address.group(2).strip()\n",
    "                    premises_list.append(Premises(premises_number, premises_address, '', '', '', ''))\n",
    "\n",
    "            # Process premises details\n",
    "            merged_lines = []\n",
    "            temp_line = ''\n",
    "            for line in lines:\n",
    "                if re.match(r'^\\d{3}\\s+', line):\n",
    "                    if temp_line:\n",
    "                        merged_lines.append(temp_line.strip())\n",
    "                    temp_line = line\n",
    "                else:\n",
    "                    temp_line += ' ' + line\n",
    "            if temp_line:\n",
    "                merged_lines.append(temp_line.strip())\n",
    "\n",
    "            data = \"\\n\".join(merged_lines)\n",
    "            matches = premises_details_re.findall(data)\n",
    "\n",
    "            for match in matches:\n",
    "                premises_number = match[0].strip()\n",
    "                blanket_and_limit = f\"${match[1].strip()}\"\n",
    "                valuation = match[2].strip()\n",
    "                coinsurance = match[3] + '%'\n",
    "                inflation_guard = match[4] + '%'\n",
    "                premises_list.append(Premises(premises_number, '', blanket_and_limit, valuation, coinsurance, inflation_guard))\n",
    "\n",
    "            \n",
    "            # Extract Named Insured and Mailing Address\n",
    "            pre_index = [i + 1 for i, x in enumerate(lines) if \"Named Insured and Mailing Address:\" in x]  \n",
    "            pre_index1 = [i + 1 for i, x in enumerate(lines) if \"Named Insured:\" in x]  \n",
    "            pre_index2 = [i + 1 for i, x in enumerate(lines) if \"Drivers and household residents\" in x]\n",
    "            if pre_index:  \n",
    "                Named_Insured_Mailing_Address.append(lines[pre_index[0]])  \n",
    "                found_named_insured = True\n",
    "                # if found_named_insured:\n",
    "                #     break\n",
    "            elif pre_index1:  \n",
    "                Named_Insured_Mailing_Address.append(lines[pre_index1[0]])  \n",
    "                found_named_insured = True  \n",
    "            elif pre_index2:  \n",
    "                Named_Insured_Mailing_Address.append(lines[pre_index2[0]])  \n",
    "                found_named_insured = True\n",
    "\n",
    "            # Extract Policy Number\n",
    "            if not found_policy_number:  \n",
    "                pro_index = [i for i, x in enumerate(lines) if \"Policy Number:\" in x]\n",
    "                pro1_index = [i+1 for i, x in enumerate(lines) if \"Policy Number:\" in x]\n",
    "                if pro_index:\n",
    "                    if lines[pro_index[0]] != \"Policy Number:\":\n",
    "                        Policy_Number.append(lines[pro_index[0]])\n",
    "                        found_policy_number = True        \n",
    "                    else:\n",
    "                        Policy_Number.append(lines[pro1_index[0]])  \n",
    "                        found_policy_number = True\n",
    "            \n",
    "            # Extract Effective Dates\n",
    "            if not found_effective_from:  \n",
    "                pr_index = [i for i, x in enumerate(lines) if \"Policy Effective \" in x]  \n",
    "                pr_index1 = [i for i, x in enumerate(lines) if \"Policy Period:\" in x]  \n",
    "                if pr_index:  \n",
    "                    Effective.append(lines[pr_index[0]])  \n",
    "                    if pr_index[0] + 1 < len(lines):  \n",
    "                        Effective.append(lines[pr_index[0] + 1])  \n",
    "                    found_effective_from = True  \n",
    "                if pr_index1:  \n",
    "                    Effective.append(lines[pr_index1[0]])  \n",
    "                    if pr_index1[0] + 1 < len(lines):  \n",
    "                        Effective.append(lines[pr_index1[0] + 1])  \n",
    "                    found_effective_from = True\n",
    "            # if all([found_named_insured, found_policy_number, found_effective_from]):\n",
    "            #     break \n",
    "            \n",
    "\n",
    "            # Extract Coverage Details\n",
    "            index = [i for i, x in enumerate(lines) if \"This policy consists of the following coverage parts: \" in x]\n",
    "            if index:\n",
    "                start_line = index[0] + 1\n",
    "                for line in lines[start_line:]:\n",
    "                    match2 = amount_re.search(line)\n",
    "                    if match2:\n",
    "                        coverage = match2.group(1).strip()\n",
    "                        premium = match2.group(2).strip() if match2.group(2) else \"Not Covered\"\n",
    "                        lines_list1.append(Line(Commercial_Package_Policy=coverage, Premium=premium))\n",
    "                    \n",
    "                    match3 = total_re.search(line)\n",
    "                    if match3:\n",
    "                        total_premium = match3.group(1).strip()\n",
    "                        lines_list1.append(Line(\"Estimated Total Premium\", total_premium))\n",
    "            \n",
    "            \n",
    "            for line in lines:\n",
    "                match1 = total_re1.search(line)\n",
    "                match = amount_re1.search(line)\n",
    "\n",
    "                if match:  \n",
    "                    coverage = match.group(1).strip()  \n",
    "                    premium1 = match.group(2).strip() if match.group(2) else None  \n",
    "                    premium2 = match.group(3).strip() if match.group(3) else None  \n",
    "                    premium3 = match.group(4).strip() if match.group(4) else None  \n",
    "                    lines_list.append(CoverageDetails(Coverage=coverage, Premium1=premium1, Premium2=premium2, Premium3=premium3))\n",
    "\n",
    "                if match1:  \n",
    "                    coverage = match1.group(1).strip()  \n",
    "                    premium1 = match1.group(2).strip() if match1.group(2) else None\n",
    "                    premium2 = match1.group(3).strip() if match1.group(3) else None  \n",
    "                    premium3 = match1.group(4).strip() if match1.group(4) else None  \n",
    "                    lines_list.append(CoverageDetails(Coverage=coverage, Premium1=premium1, Premium2=premium2, Premium3=premium3))\n",
    "            premium_match = premium_pattern.search(text)  \n",
    "            if premium_match:  \n",
    "                premiums.append({'Premium1': premium_match.group(1), 'Premium2': premium_match.group(2), 'Premium3': premium_match.group(3)})\n",
    "\n",
    "            # Extract Persons and Vehicles Information\n",
    "            for line in lines:\n",
    "                person_match = person_re.search(line)  \n",
    "                vehicle_match = vehicle_re.search(line)\n",
    "\n",
    "                if person_match:  \n",
    "                    name, dob, status = person_match.groups()  \n",
    "                    persons_list.append(Person(name.strip(), dob.strip(), status.strip()))  \n",
    "\n",
    "                if vehicle_match:  \n",
    "                    description, vin = vehicle_match.groups()  \n",
    "                    vehicles_list.append(Vehicle(description.strip(), vin.strip())) \n",
    "\n",
    "# Convert lists to DataFrames\n",
    "premium_df = pd.DataFrame(premiums)\n",
    "persons_df = pd.DataFrame(persons_list)\n",
    "vehicles_df = pd.DataFrame(vehicles_list)\n",
    "coverage_df1 = pd.DataFrame(lines_list1)\n",
    "coverage_df0 = pd.DataFrame(lines_list)\n",
    "coverage_df = pd.DataFrame(coverages_list)\n",
    "df = pd.DataFrame(lines_list2)\n",
    "def convert_to_float(premium_str):  \n",
    "    return float(premium_str.replace('$', '').replace(',', ''))  \n",
    "\n",
    "# Calculate total premium if the DataFrame is not empty  \n",
    "if not premium_df.empty:  \n",
    "    premium_df['Total Premium'] = premium_df.apply(lambda row: sum([convert_to_float(row['Premium1']),  \n",
    "                                                                     convert_to_float(row['Premium2']),  \n",
    "                                                                     convert_to_float(row['Premium3'])]), axis=1)  \n",
    "    \n",
    "    # Add a new first column with the value \"Premium by Vehicle:\"  \n",
    "    premium_df.insert(0, 'Description', 'Premium by Vehicle:')\n",
    "# Print the DataFrames\n",
    "# Determine the maximum length among the lists\n",
    "max_length = max(len(Named_Insured_Mailing_Address), len(Policy_Number), len(Effective))\n",
    "\n",
    "# Extend the lists to match the maximum length\n",
    "Named_Insured_Mailing_Address.extend([None] * (max_length - len(Named_Insured_Mailing_Address)))\n",
    "Policy_Number.extend([None] * (max_length - len(Policy_Number)))\n",
    "Effective.extend([None] * (max_length - len(Effective)))\n",
    "\n",
    "# Create the DataFrame\n",
    "policy_data = pd.DataFrame({\n",
    "    'Named Insured': Named_Insured_Mailing_Address,\n",
    "    \"Policy Number\": Policy_Number,\n",
    "    \"Effective\": Effective,\n",
    "}).drop_duplicates()\n",
    "##0\n",
    "print(\"\\nPremium DataFrame:\")  \n",
    "print(premium_df)\n",
    "##-1\n",
    "print(\"\\ncoveragesss DataFrame:\")\n",
    "print(df)\n",
    "# Print the DataFrame for verification\n",
    "##1dd\n",
    "print(\"Policy_data\")\n",
    "print(policy_data)\n",
    "##2\n",
    "print(\"Persons DataFrame:\")\n",
    "print(persons_df)\n",
    "##3\n",
    "print(\"\\nVehicles DataFrame:\")\n",
    "print(vehicles_df)\n",
    "##4dd\n",
    "print(\"\\nPolicy DataFrame:\")\n",
    "print(coverage_df1)\n",
    "##5\n",
    "print(\"\\nPolicy6 DataFrame:\")\n",
    "print(coverage_df0)\n",
    "##6dd\n",
    "\n",
    "print(\"\\nCoverages DataFrame:\")\n",
    "print(coverage_df)\n",
    "##7dd\n",
    "premises_df = pd.DataFrame(premises_list).drop_duplicates()\n",
    "print(\"Premises DataFrame:\")\n",
    "print(premises_df)\n",
    "excel_file = 'insurance_report_combined.xlsx'  \n",
    "with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:  \n",
    "    policy_data.to_excel(writer, index=False, sheet_name='Insurance Report', startrow=2)  \n",
    "    \n",
    "    # Access the workbook and the worksheet  \n",
    "    workbook = writer.book  \n",
    "    worksheet = writer.sheets['Insurance Report']  \n",
    "\n",
    "    # Add headings for the policy report  \n",
    "    report_heading = \"Insurance Report\"  \n",
    "    worksheet.merge_cells('A1:C1')  \n",
    "    cell = worksheet.cell(row=1, column=1)  \n",
    "    cell.value = report_heading  \n",
    "    cell.alignment = Alignment(horizontal='center', vertical='center')  \n",
    "    cell.font = Font(bold=True)  \n",
    "\n",
    "    # Add border style for the columns  \n",
    "    border = Border(left=Side(style='thin'), right=Side(style='thin'), top=Side(style='thin'), bottom=Side(style='thin'))  \n",
    "    \n",
    "    min_width = 20  # Minimum column width  \n",
    "\n",
    "    # Set column widths and apply styles  \n",
    "    for col in worksheet.columns:  \n",
    "        if not col:  # If the column is empty, skip  \n",
    "            continue  \n",
    "        \n",
    "        max_length = 0  \n",
    "        column_letter = get_column_letter(col[0].column)  \n",
    "\n",
    "        for cell in col:  \n",
    "            if cell.value:  # Check if the cell is not empty  \n",
    "                max_length = max(max_length, len(str(cell.value)))  # Update max_length  \n",
    "            \n",
    "        adjusted_width = max(max_length + 2, min_width)  # Add some extra space  \n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width  \n",
    "        \n",
    "        # Set borders for each cell in the column  \n",
    "        for cell in col:  \n",
    "            cell.border = border  \n",
    "\n",
    "    # Make header row bold (now it’s row 3 after writing the policy data)  \n",
    "    for cell in worksheet[2]:  # Row indexing starts from 1  \n",
    "        cell.font = Font(bold=True)  # Make the header bold  \n",
    "\n",
    "    # Loop to append additional DataFrames   \n",
    "    last_row = worksheet.max_row + 2  \n",
    "    for df in [premises_df, coverage_df, coverage_df1, coverage_df0, persons_df, premium_df, df, vehicles_df]:  \n",
    "        df.to_excel(writer, index=False, sheet_name='Insurance Report', startrow=last_row) \n",
    "        \n",
    "        \n",
    "\n",
    "        # Update last_row after writing each DataFrame  \n",
    "        last_row = worksheet.max_row + 2  \n",
    "\n",
    "        # Apply the same styling and formatting to each appended DataFrame  \n",
    "        for col in worksheet.iter_cols(min_row=last_row):  \n",
    "            if not col:  # If the column is empty, skip  \n",
    "                continue  \n",
    "            \n",
    "            max_length = 0  \n",
    "            column_letter = get_column_letter(col[0].column)\n",
    "        for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row, min_col=1, max_col=worksheet.max_column):\n",
    "            for cell in row:\n",
    "                cell.border = border\n",
    "    \n",
    "\n",
    "            for cell in col:  \n",
    "                if cell.value:  # Only check non-empty cells  \n",
    "                    max_length = max(max_length, len(str(cell.value)))  \n",
    "\n",
    "            adjusted_width = max(max_length + 2, min_width)  \n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width  \n",
    "\n",
    "            # Apply borders  \n",
    "            for cell in col:  \n",
    "                cell.border = border  \n",
    "\n",
    "    # Save changes  \n",
    "    workbook.save(excel_file)  \n",
    "\n",
    "print(f'Data successfully written to {excel_file}') \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d06caba-e1a7-4c3d-bfc7-bea09ac1e937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage DataFrame from part 1:\n",
      "                     Commercial_Package_Policy  Premium_Policy  \\\n",
      "0                                     Property          8732.0   \n",
      "1                                        Crime           491.0   \n",
      "2                                         Auto             0.0   \n",
      "3                            General Liability         18584.0   \n",
      "4  Religious Organization Management Liability           754.0   \n",
      "5                             Excess Liability             0.0   \n",
      "6                      Taxes, Fees, Surcharges             0.0   \n",
      "7                      Estimated Total Premium         28561.0   \n",
      "\n",
      "   Premium_Policy1  Difference  \n",
      "0           8732.0         0.0  \n",
      "1            491.0         0.0  \n",
      "2              0.0         0.0  \n",
      "3          18584.0         0.0  \n",
      "4            754.0         0.0  \n",
      "5              0.0         0.0  \n",
      "6              0.0         0.0  \n",
      "7          28561.0         0.0  \n",
      "\n",
      "Coverage DataFrame from part 2:\n",
      "Empty DataFrame\n",
      "Columns: [difference1_1, difference2_1, difference3_1]\n",
      "Index: []\n",
      "Warning: Column Premium1 not found in the DataFrame.\n",
      "Warning: Column Premium2 not found in the DataFrame.\n",
      "Warning: Column Premium3 not found in the DataFrame.\n",
      "Warning: Column Premium1_1 not found in the DataFrame.\n",
      "Warning: Column Premium2_1 not found in the DataFrame.\n",
      "Warning: Column Premium3_1 not found in the DataFrame.\n",
      "No valid premium data found. DataFrame is empty.\n",
      "Columns in df1: []\n",
      "Columns in df2: []\n",
      "DF1 contents:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "DF2 contents:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Coverage_Type column not found in df1\n",
      "Coverage_Type column not found in df2\n",
      "Merged DataFrame structure before cleaning:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Merged DataFrame columns:\n",
      " []\n",
      "Necessary columns are missing in the merged DataFrame.\n",
      "Policy_data\n",
      "                                        Named Insured           Policy Number  \\\n",
      "0                                      MAS PHILY, INC  GRNU-RP-0018422-00/000   \n",
      "1                                      MAS PHILY, INC                    None   \n",
      "2                                      MAS PHILY, INC                    None   \n",
      "6   a. An actual, attempted, or threatened “violen...                    None   \n",
      "8                       Policy Period: From06/15/2020                    None   \n",
      "9                      Policy Period: From 06/15/2020                    None   \n",
      "10  Policy No. or Type of Policy: GRNU-RP-0018422-...                    None   \n",
      "11                                               None                    None   \n",
      "\n",
      "                         Effective  \n",
      "0   Policy Period: From 06-15-2020  \n",
      "1                    To 06-15-2021  \n",
      "2                             None  \n",
      "6                             None  \n",
      "8                             None  \n",
      "9                             None  \n",
      "10                            None  \n",
      "11                            None  \n",
      "merged_df\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Data successfully written to insurance_report_combined.xlsx\n"
     ]
    }
   ],
   "source": [
    "### Comparison  \n",
    "import re\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Border, Side, Alignment, Font\n",
    "\n",
    "# Define namedtuples for different scenarios\n",
    "Line = namedtuple('Line', 'Commercial_Package_Policy Premium_Policy Premium_Policy1')\n",
    "CoverageDetails = namedtuple('CoverageDetails', 'Coverage Premium1 Premium2 Premium3 Premium1_1 Premium2_1 Premium3_1')\n",
    "Line1 = namedtuple('Line1', 'Coverage_Type Limit Premium Limit1 Premium1')\n",
    "PremiumDetails = namedtuple('PremiumDetails', 'Premium_Coverage Premium1 Premium2 Premium3 Premium1_1 Premium2_1 Premium3_1')\n",
    "# List of PDF files to process\n",
    "files1 = ['4.pdf', '4.pdf']  # PDF files for the first part\n",
    "\n",
    "\n",
    "# Regex patterns for part 1\n",
    "amount_re = re.compile(r'([A-Za-z\\s,]+?)(?:\\s+\\$([\\d,]+\\.\\d{2})| Not Covered|:\\s*\\$.00)')\n",
    "total_re = re.compile(r'Estimated Total Premium:\\s*\\$([\\d,]+\\.\\d{2})')\n",
    "amount_re2 = re.compile(r'([A-Za-z\\s$$]+)\\s+\\$([\\d,]+(?:\\.\\d{2})?)')\n",
    "amount_re1 = re.compile(r'([A-Za-z\\s/()]+)\\s+(\\$\\d{1,3}(?:,\\d{3})*(?:/\\s*\\$?\\d{1,3}(?:,\\d{3})*)?)?\\s+(\\$\\d{1,3}(?:,\\d{3})*(?:/\\s*\\$?\\d{1,3}(?:,\\d{3})*)?)?\\s+(\\$\\d{1,3}(?:,\\d{3})*(?:/\\s*\\$?\\d{1,3}(?:,\\d{3})*)?)?(?:\\s+Included)?')\n",
    "total_re1 = re.compile(r'([A-Za-z\\s,]+?)(?:\\s+\\$([\\d,]+\\.\\d{2})(?:\\s+\\$([\\d,]+\\.\\d{2}))(?:\\s+\\$([\\d,]+\\.\\d{2})))')\n",
    "premium_pattern = re.compile(r'Premium by Vehicle\\s+(\\$[\\d,]+\\.\\d{2})\\s+(\\$[\\d,]+\\.\\d{2})\\s+(\\$[\\d,]+\\.\\d{2})')\n",
    "pattern = re.compile(r'^(.*?)\\s+\\$(.*?)\\s+(\\d+(?:,\\d+)?(?:\\.\\d+)?)\\s*(\\d+|$)', re.MULTILINE)  \n",
    "vehicle_premium_pattern = re.compile(r\"Total premium for \\d{4} [A-Z]+\\s*[A-Z]*\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\")  \n",
    "total_policy_premium_pattern = re.compile(r\"Total Policy Premium:\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\")  \n",
    "subtotal_policy_premium_pattern = re.compile(r\"Subtotal policy premium\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\")  \n",
    "total_6_month_premium_pattern = re.compile(r\"Total 6 month policy premium and fees\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\")  \n",
    "\n",
    "# Initialize lists to hold the extracted data for part 1\n",
    "\n",
    "lines_list1 = []\n",
    "lines_list2 = []\n",
    "lines_list3 = []\n",
    "premiums_first_pdf = []  \n",
    "premiums_second_pdf = []\n",
    "lines_list_first_pdf = []  \n",
    "lines_list_second_pdf = []\n",
    "Named_Insured_Mailing_Address = []  \n",
    "Policy_Number = []  \n",
    "Effective = []\n",
    "found_named_insured = False  \n",
    "found_policy_number = False  \n",
    "found_effective_from = False\n",
    "# Process the first PDF file for part 1\n",
    "with pdfplumber.open(files1[0]) as pdf:  \n",
    "    for page in pdf.pages:  \n",
    "        text = page.extract_text()  \n",
    "        if text:\n",
    "            \n",
    "            premium_match = premium_pattern.search(text)  \n",
    "            if premium_match:  \n",
    "                premium1 = premium_match.group(1)  \n",
    "                premium2 = premium_match.group(2)  \n",
    "                premium3 = premium_match.group(3)  \n",
    "                premiums_first_pdf.append((premium1, premium2, premium3))\n",
    "            lines = text.split('\\n')\n",
    "            for line in lines:\n",
    "                match = amount_re1.search(line)\n",
    "                match1 = total_re1.search(line)\n",
    "                if match:\n",
    "                    coverage = match.group(1).strip()  \n",
    "                    premium1 = match.group(2).strip() if match.group(2) else None  \n",
    "                    premium2 = match.group(3).strip() if match.group(3) else None  \n",
    "                    premium3 = match.group(4).strip() if match.group(4) else None  \n",
    "                    lines_list_first_pdf.append(CoverageDetails(Coverage=coverage, Premium1=premium1, Premium2=premium2, Premium3=premium3, Premium1_1=None, Premium2_1=None, Premium3_1=None))\n",
    "                elif match1:\n",
    "                    coverage = match1.group(1).strip()\n",
    "                    premium1 = match1.group(2).strip() if match1.group(2) else None\n",
    "                    premium2 = match1.group(3).strip() if match1.group(3) else None\n",
    "                    premium3 = match1.group(4).strip() if match1.group(4) else None\n",
    "                    lines_list_first_pdf.append(CoverageDetails(Coverage=coverage, Premium1=premium1, Premium2=premium2, Premium3=premium3, Premium1_1=None, Premium2_1=None, Premium3_1=None))\n",
    "            pre_index = [i + 1 for i, x in enumerate(lines) if \"Named Insured and Mailing Address:\" in x]  \n",
    "            pre_index1 = [i + 1 for i, x in enumerate(lines) if \"Named Insured:\" in x]  \n",
    "            pre_index2 = [i + 1 for i, x in enumerate(lines) if \"Drivers and household residents\" in x]\n",
    "            if pre_index:  \n",
    "                Named_Insured_Mailing_Address.append(lines[pre_index[0]])  \n",
    "                found_named_insured = True\n",
    "                # if found_named_insured:\n",
    "                #     break\n",
    "            elif pre_index1:  \n",
    "                Named_Insured_Mailing_Address.append(lines[pre_index1[0]])  \n",
    "                found_named_insured = True  \n",
    "            elif pre_index2:  \n",
    "                Named_Insured_Mailing_Address.append(lines[pre_index2[0]])  \n",
    "                found_named_insured = True\n",
    "\n",
    "            # Extract Policy Number\n",
    "            if not found_policy_number:  \n",
    "                pro_index = [i for i, x in enumerate(lines) if \"Policy Number:\" in x]\n",
    "                pro1_index = [i+1 for i, x in enumerate(lines) if \"Policy Number:\" in x]\n",
    "                if pro_index:\n",
    "                    if lines[pro_index[0]] != \"Policy Number:\":\n",
    "                        Policy_Number.append(lines[pro_index[0]])\n",
    "                        found_policy_number = True        \n",
    "                    else:\n",
    "                        Policy_Number.append(lines[pro1_index[0]])  \n",
    "                        found_policy_number = True\n",
    "            \n",
    "            # Extract Effective Dates\n",
    "            if not found_effective_from:  \n",
    "                pr_index = [i for i, x in enumerate(lines) if \"Policy Effective \" in x]  \n",
    "                pr_index1 = [i for i, x in enumerate(lines) if \"Policy Period:\" in x]  \n",
    "                if pr_index:  \n",
    "                    Effective.append(lines[pr_index[0]])  \n",
    "                    if pr_index[0] + 1 < len(lines):  \n",
    "                        Effective.append(lines[pr_index[0] + 1])  \n",
    "                    found_effective_from = True  \n",
    "                if pr_index1:  \n",
    "                    Effective.append(lines[pr_index1[0]])  \n",
    "                    if pr_index1[0] + 1 < len(lines):  \n",
    "                        Effective.append(lines[pr_index1[0] + 1])  \n",
    "                    found_effective_from = True\n",
    "            #print(\"Extracted text for PDF 1:\", lines)  # Debug print\n",
    "            \n",
    "            # Processing coverage parts\n",
    "            index = [i for i, x in enumerate(lines) if \"This policy consists of the following coverage parts: \" in x]\n",
    "            if index:\n",
    "                start_line = index[0] + 1\n",
    "                for line in lines[start_line:]:\n",
    "                    match2 = amount_re.search(line)\n",
    "                    if match2:\n",
    "                        coverage = match2.group(1).strip()\n",
    "                        premium = match2.group(2).strip() if match2.group(2) else \"Not Covered\"\n",
    "                        lines_list1.append(Line(Commercial_Package_Policy=coverage, Premium_Policy=premium, Premium_Policy1=\"\"))\n",
    "                        #print(f\"Matched coverage: {coverage}, premium: {premium}\")  # Debug print\n",
    "\n",
    "                    match3 = total_re.search(line)\n",
    "                    if match3:\n",
    "                        total_premium = match3.group(1).strip()\n",
    "                        lines_list1.append(Line(\"Estimated Total Premium\", total_premium, \"\"))\n",
    "            index1 = [i + 1 for i, x in enumerate(lines) if \"Primary use of the vehicle: Pleasure/Personal\" in x]\n",
    "            if index1:\n",
    "                start_line = index1[0]\n",
    "                for line in lines[start_line:]:\n",
    "                    match4 = pattern.match(line)\n",
    "                    vehicle_premium_match = vehicle_premium_pattern.search(line)\n",
    "                    total_policy_premium_match = total_policy_premium_pattern.search(line)\n",
    "                    subtotal_policy_premium_match = subtotal_policy_premium_pattern.search(line)\n",
    "                    total_6_month_premium_match = total_6_month_premium_pattern.search(line)\n",
    "                    \n",
    "                    if match4:\n",
    "                        coverage_title = match4.group(1).strip()\n",
    "                        limits = match4.group(2).strip()\n",
    "                        notes = match4.group(3).strip() if match4.group(3) is not None else \"\"\n",
    "                        lines_list2.append(Line1(Coverage_Type=coverage_title, Limit=limits, Premium=notes, Limit1=None, Premium1=None))\n",
    "\n",
    "                    if vehicle_premium_match:\n",
    "                        lines_list2.append(Line1(Coverage_Type=\"Vehicle Premium\", Limit=None, Premium=vehicle_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if total_policy_premium_match:\n",
    "                        lines_list2.append(Line1(Coverage_Type=\"Total Policy Premium\", Limit=None, Premium=total_policy_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if subtotal_policy_premium_match:\n",
    "                        lines_list2.append(Line1(Coverage_Type=\"Subtotal Policy Premium\", Limit=None, Premium=subtotal_policy_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if total_6_month_premium_match:\n",
    "                        lines_list2.append(Line1(Coverage_Type=\"Total 6 Month Premium\", Limit=None, Premium=total_6_month_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "                        #print(f\"Matched total premium: {total_premium}\")  # Debug print\n",
    "df1 = pd.DataFrame(lines_list2)\n",
    "           \n",
    "\n",
    "# Process the second PDF file and update Premium1 for part 1\n",
    "with pdfplumber.open(files1[1]) as pdf:  \n",
    "    for page in pdf.pages:  \n",
    "        text = page.extract_text()  \n",
    "        if text:\n",
    "            premium_match = premium_pattern.search(text)  \n",
    "            if premium_match:  \n",
    "                premium1_1 = premium_match.group(1)  \n",
    "                premium2_1 = premium_match.group(2)  \n",
    "                premium3_1 = premium_match.group(3)  \n",
    "                premiums_second_pdf.append((premium1_1, premium2_1, premium3_1))\n",
    "            lines = text.split('\\n')\n",
    "            for line in lines:\n",
    "                match = amount_re1.search(line)\n",
    "                match1 = total_re1.search(line)\n",
    "                if match:\n",
    "                    coverage = match.group(1).strip()  \n",
    "                    premium1 = match.group(2).strip() if match.group(2) else None  \n",
    "                    premium2 = match.group(3).strip() if match.group(3) else None  \n",
    "                    premium3 = match.group(4).strip() if match.group(4) else None  \n",
    "                    lines_list_second_pdf.append(CoverageDetails(Coverage=coverage, Premium1=premium1, Premium2=premium2, Premium3=premium3, Premium1_1=None, Premium2_1=None, Premium3_1=None))\n",
    "                elif match1:\n",
    "                    coverage = match1.group(1).strip()\n",
    "                    premium1 = match1.group(2).strip() if match1.group(2) else None\n",
    "                    premium2 = match1.group(3).strip() if match1.group(3) else None\n",
    "                    premium3 = match1.group(4).strip() if match1.group(4) else None\n",
    "                    lines_list_second_pdf.append(CoverageDetails(Coverage=coverage, Premium1=premium1, Premium2=premium2, Premium3=premium3, Premium1_1=None, Premium2_1=None, Premium3_1=None))\n",
    "            #print(\"Extracted text for PDF 2:\", lines)  # Debug print\n",
    "            \n",
    "\n",
    "            # Processing coverage parts\n",
    "            index = [i for i, x in enumerate(lines) if \"This policy consists of the following coverage parts: \" in x]\n",
    "            if index:\n",
    "                start_line = index[0] + 1\n",
    "                for i, line in enumerate(lines[start_line:]):\n",
    "                    match2 = amount_re.search(line)\n",
    "                    if match2 and i < len(lines_list1):  \n",
    "                        premium1 = match2.group(2).strip() if match2.group(2) else \"Not Covered\"\n",
    "                        lines_list1[i] = lines_list1[i]._replace(Premium_Policy1=premium1)  \n",
    "                        #print(f\"Updated line {i} with Premium_Policy1: {premium1}\")  # Debug print\n",
    "\n",
    "                    match3 = total_re.search(line)\n",
    "                    if match3 and i < len(lines_list1):  \n",
    "                        total_premium1 = match3.group(1).strip()\n",
    "                        if lines_list1[i].Commercial_Package_Policy == \"Estimated Total Premium\":\n",
    "                            lines_list1[i] = lines_list1[i]._replace(Premium_Policy1=total_premium1)\n",
    "            index2 = [i + 1 for i, x in enumerate(lines) if \"Primary use of the vehicle: Pleasure/Personal\" in x]\n",
    "            if index2:\n",
    "                start_line = index2[0]\n",
    "                for line in lines[start_line:]:\n",
    "                    match4 = pattern.match(line)\n",
    "                    vehicle_premium_match = vehicle_premium_pattern.search(line)\n",
    "                    total_policy_premium_match = total_policy_premium_pattern.search(line)\n",
    "                    subtotal_policy_premium_match = subtotal_policy_premium_pattern.search(line)\n",
    "                    total_6_month_premium_match = total_6_month_premium_pattern.search(line)\n",
    "                    \n",
    "                    if match3:\n",
    "                        coverage_title = match4.group(1).strip()\n",
    "                        limits = match4.group(2).strip()\n",
    "                        notes = match4.group(3).strip() if match4.group(3) is not None else \"\"\n",
    "                        lines_list3.append(Line1(Coverage_Type=coverage_title, Limit=limits, Premium=notes, Limit1=None, Premium1=None))\n",
    "\n",
    "                    if vehicle_premium_match:\n",
    "                        lines_list3.append(Line1(Coverage_Type=\"Vehicle Premium\", Limit=None, Premium=vehicle_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if total_policy_premium_match:\n",
    "                        lines_list3.append(Line1(Coverage_Type=\"Total Policy Premium\", Limit=None, Premium=total_policy_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if subtotal_policy_premium_match:\n",
    "                        lines_list3.append(Line1(Coverage_Type=\"Subtotal Policy Premium\", Limit=None, Premium=subtotal_policy_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if total_6_month_premium_match:\n",
    "                        lines_list3.append(Line1(Coverage_Type=\"Total 6 Month Premium\", Limit=None, Premium=total_6_month_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "                            #print(f\"Updated total premium for Estimated Total Premium: {total_premium1}\")  # Debug print\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(lines_list3)            \n",
    "               \n",
    "# Convert to DataFrame for part 1\n",
    "coverage_df1 = pd.DataFrame(lines_list1)\n",
    "df = pd.DataFrame(lines_list2)\n",
    "# Verify DataFrame columns and data\n",
    "# print(\"DataFrame for part 1:\", coverage_df1)\n",
    "\n",
    "# Check if DataFrame is empty\n",
    "if coverage_df1.empty:\n",
    "    print(\"No data was collected for coverage_df1.\")\n",
    "else:\n",
    "    # Handle empty strings and non-numeric values in 'Premium' and 'Premium1' for part 1\n",
    "    coverage_df1['Premium_Policy'] = coverage_df1['Premium_Policy'].replace(['Not Covered', ''], '0').str.replace(',', '').astype(float)\n",
    "    coverage_df1['Premium_Policy1'] = coverage_df1['Premium_Policy1'].replace(['Not Covered', ''], '0').str.replace(',', '').astype(float)\n",
    "\n",
    "    # Add a new column 'Difference' by subtracting Premium1 from Premium for part 1\n",
    "    coverage_df1['Difference'] = coverage_df1['Premium_Policy'] - coverage_df1['Premium_Policy1']\n",
    "coverage_df2 = pd.DataFrame(lines_list_first_pdf)\n",
    "\n",
    "# Verify DataFrame columns for coverage_df2\n",
    "# print(\"DataFrame columns for part 2:\", coverage_df2.columns)\n",
    "\n",
    "# Match and update the DataFrame with data from the second PDF for part 2\n",
    "for entry2 in lines_list_second_pdf:\n",
    "    matched = False\n",
    "    for i, row in coverage_df2.iterrows():\n",
    "        if row['Coverage'] == entry2.Coverage:\n",
    "            coverage_df2.at[i, 'Premium1_1'] = entry2.Premium1\n",
    "            coverage_df2.at[i, 'Premium2_1'] = entry2.Premium2\n",
    "            coverage_df2.at[i, 'Premium3_1'] = entry2.Premium3\n",
    "            matched = True\n",
    "            break\n",
    "    if not matched:\n",
    "        print(f\"Coverage '{entry2.Coverage}' from second PDF did not match any entry in the first PDF.\")\n",
    "\n",
    "# Add columns for differences for part 2\n",
    "coverage_df2['difference1_1'] = None\n",
    "coverage_df2['difference2_1'] = None\n",
    "coverage_df2['difference3_1'] = None\n",
    "\n",
    "# Calculate differences for part 2\n",
    "for i, row in coverage_df2.iterrows():\n",
    "    def parse_premium(premium_str):\n",
    "        if premium_str is None:\n",
    "            return None\n",
    "        numeric_parts = re.findall(r'\\d+(?:,\\d{3})*(?:\\.\\d{2})?', premium_str)\n",
    "        if numeric_parts:\n",
    "            return float(numeric_parts[0].replace(',', ''))\n",
    "        return None\n",
    "\n",
    "    premium1 = parse_premium(row['Premium1'])\n",
    "    premium1_1 = parse_premium(row['Premium1_1'])\n",
    "    premium2 = parse_premium(row['Premium2'])\n",
    "    premium2_1 = parse_premium(row['Premium2_1'])\n",
    "    premium3 = parse_premium(row['Premium3'])\n",
    "    premium3_1 = parse_premium(row['Premium3_1'])\n",
    "    \n",
    "    coverage_df2.at[i, 'difference1_1'] = (premium1_1 - premium1) if premium1 is not None and premium1_1 is not None else None\n",
    "    coverage_df2.at[i, 'difference2_1'] = (premium2_1 - premium2) if premium2 is not None and premium2_1 is not None else None\n",
    "    coverage_df2.at[i, 'difference3_1'] = (premium3_1 - premium3) if premium3 is not None and premium3_1 is not None else None\n",
    "\n",
    "# Display the updated DataFrames\n",
    "\n",
    "print(\"Coverage DataFrame from part 1:\")\n",
    "print(coverage_df1)\n",
    "print(\"\\nCoverage DataFrame from part 2:\")\n",
    "print(coverage_df2)\n",
    "\n",
    "min_length = min(len(premiums_first_pdf), len(premiums_second_pdf))  \n",
    "# print(f\"Minimum length of premiums: {min_length}\")  # Debug print  \n",
    "\n",
    "premiums_first_pdf = premiums_first_pdf[:min_length]  \n",
    "premiums_second_pdf = premiums_second_pdf[:min_length]  \n",
    "\n",
    "# Create PremiumDetails instances  \n",
    "premium_details_list = [  \n",
    "    PremiumDetails(  \n",
    "        Premium_Coverage=\"Premium of Vehicles\",  \n",
    "        Premium1=premiums_first_pdf[i][0],  \n",
    "        Premium2=premiums_first_pdf[i][1],  \n",
    "        Premium3=premiums_first_pdf[i][2],  \n",
    "        Premium1_1=premiums_second_pdf[i][0],  \n",
    "        Premium2_1=premiums_second_pdf[i][1],  \n",
    "        Premium3_1=premiums_second_pdf[i][2]  \n",
    "    )  \n",
    "    for i in range(min_length)  \n",
    "]  \n",
    "\n",
    "# Check if the premium details are populated  \n",
    "# print(\"Premium details list:\", premium_details_list)  \n",
    "\n",
    "# Create a DataFrame from the list of PremiumDetails  \n",
    "premium_df = pd.DataFrame(premium_details_list)  \n",
    "\n",
    "# Verify the DataFrame structure  \n",
    "# print(\"DataFrame structure:\\n\", premium_df.head())  \n",
    "\n",
    "# Convert premium columns to numeric values, if they exist  \n",
    "premium_columns = ['Premium1', 'Premium2', 'Premium3', 'Premium1_1', 'Premium2_1', 'Premium3_1']  \n",
    "for col in premium_columns:  \n",
    "    if col in premium_df.columns:  # Check if the column exists  \n",
    "        premium_df[col] = premium_df[col].replace({'\\$': '', ',': ''}, regex=True).astype(float)  \n",
    "    else:  \n",
    "        print(f\"Warning: Column {col} not found in the DataFrame.\")  \n",
    "\n",
    "# Proceed if DataFrame has required columns  \n",
    "if len(premium_df.columns) > 0:  \n",
    "    # Add TotalPremium1 and TotalPremium2 columns  \n",
    "    premium_df['TotalPremium1'] = premium_df[['Premium1', 'Premium2', 'Premium3']].sum(axis=1)  \n",
    "    premium_df['TotalPremium2'] = premium_df[['Premium1_1', 'Premium2_1', 'Premium3_1']].sum(axis=1)  \n",
    "\n",
    "    # Add Difference column  \n",
    "    premium_df['Difference'] = premium_df['TotalPremium1'] - premium_df['TotalPremium2']  \n",
    "\n",
    "    # Print the final DataFrame  \n",
    "    print(premium_df)  \n",
    "else:  \n",
    "    print(\"No valid premium data found. DataFrame is empty.\")   \n",
    "print(\"Columns in df1:\", df1.columns.tolist())  \n",
    "print(\"Columns in df2:\", df2.columns.tolist())\n",
    "print(\"DF1 contents:\\n\", df1.head())\n",
    "print(\"DF2 contents:\\n\", df2.head())\n",
    "\n",
    "# Check if 'Coverage_Type' is in both dataframes\n",
    "if 'Coverage_Type' not in df1.columns:\n",
    "    print(\"Coverage_Type column not found in df1\")\n",
    "\n",
    "if 'Coverage_Type' not in df2.columns:\n",
    "    print(\"Coverage_Type column not found in df2\")\n",
    "\n",
    "# Merge data from the two PDFs\n",
    "merged_df = df1.copy()\n",
    "\n",
    "# Update 'Limit1' and 'Premium1' columns from df2\n",
    "for index, row in merged_df.iterrows():\n",
    "    corresponding_row = df2[df2['Coverage_Type'] == row['Coverage_Type']]\n",
    "    if not corresponding_row.empty:\n",
    "        merged_df.at[index, 'Limit1'] = corresponding_row['Limit'].values[0]\n",
    "        merged_df.at[index, 'Premium1'] = corresponding_row['Premium'].values[0]\n",
    "\n",
    "# Check merged DataFrame structure\n",
    "print(\"Merged DataFrame structure before cleaning:\\n\", merged_df.head())\n",
    "print(\"Merged DataFrame columns:\\n\", merged_df.columns.tolist()) \n",
    "\n",
    "# Function to clean and convert currency strings to floats\n",
    "def clean_currency(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace(',', '').replace('$', '')\n",
    "        try:\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return float(value) if value else None\n",
    "\n",
    "# Apply the cleaning function to Premium and Premium1 columns\n",
    "if 'Premium' in merged_df.columns and 'Premium1' in merged_df.columns:\n",
    "    merged_df['Premium'] = merged_df['Premium'].apply(clean_currency)\n",
    "    merged_df['Premium1'] = merged_df['Premium1'].apply(clean_currency)\n",
    "    conditions = merged_df['Coverage_Type'].isin([\"Vehicle Premium\", \"Subtotal Policy Premium\", \"Total 6 Month Premium\"])\n",
    "    merged_df.loc[conditions, 'Difference'] = merged_df['Premium1'] - merged_df['Premium']\n",
    "else:\n",
    "    print(\"Necessary columns are missing in the merged DataFrame.\")\n",
    "# max_length = max(len(Named_Insured_Mailing_Address), len(Policy_Number), len(Effective))\n",
    "\n",
    "# Extend the lists to match the maximum length\n",
    "Named_Insured_Mailing_Address.extend([None] * (max_length - len(Named_Insured_Mailing_Address)))\n",
    "Policy_Number.extend([None] * (max_length - len(Policy_Number)))\n",
    "Effective.extend([None] * (max_length - len(Effective)))\n",
    "\n",
    "# Create the DataFrame\n",
    "policy_data = pd.DataFrame({\n",
    "    'Named Insured': Named_Insured_Mailing_Address,\n",
    "    \"Policy Number\": Policy_Number,\n",
    "    \"Effective\": Effective,\n",
    "}).drop_duplicates()\n",
    "print(\"Policy_data\")\n",
    "print(policy_data)\n",
    "\n",
    "\n",
    "# Print the merged DataFrame to see the extracted information with the calculated differences\n",
    "print('merged_df')\n",
    "print(merged_df)\n",
    "excel_file = 'insurance_report_combined.xlsx'  \n",
    "with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:  \n",
    "    policy_data.to_excel(writer, index=False, sheet_name='Insurance Report', startrow=2)  \n",
    "    \n",
    "    # Access the workbook and the worksheet  \n",
    "    workbook = writer.book  \n",
    "    worksheet = writer.sheets['Insurance Report']  \n",
    "\n",
    "    # Add headings for the policy report  \n",
    "    report_heading = \"Insurance Report\"  \n",
    "    worksheet.merge_cells('A1:C1')  \n",
    "    cell = worksheet.cell(row=1, column=1)  \n",
    "    cell.value = report_heading  \n",
    "    cell.alignment = Alignment(horizontal='center', vertical='center')  \n",
    "    cell.font = Font(bold=True)  \n",
    "\n",
    "    # Add border style for the columns  \n",
    "    border = Border(left=Side(style='thin'), right=Side(style='thin'), top=Side(style='thin'), bottom=Side(style='thin'))  \n",
    "    \n",
    "    min_width = 20  # Minimum column width  \n",
    "\n",
    "    # Set column widths and apply styles  \n",
    "    for col in worksheet.columns:  \n",
    "        if not col:  # If the column is empty, skip  \n",
    "            continue  \n",
    "        \n",
    "        max_length = 0  \n",
    "        column_letter = get_column_letter(col[0].column)  \n",
    "\n",
    "        for cell in col:  \n",
    "            if cell.value:  # Check if the cell is not empty  \n",
    "                max_length = max(max_length, len(str(cell.value)))  # Update max_length  \n",
    "            \n",
    "        adjusted_width = max(max_length + 2, min_width)  # Add some extra space  \n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "        # Set borders for each cell in the column  \n",
    "        for cell in col:  \n",
    "            cell.border = border  \n",
    "\n",
    "    # Make header row bold (now it’s row 3 after writing the policy data)  \n",
    "    for cell in worksheet[2]:  # Row indexing starts from 1  \n",
    "        cell.font = Font(bold=True)  # Make the header bold  \n",
    "\n",
    "    # Loop to append additional DataFrames   \n",
    "    last_row = worksheet.max_row + 2  \n",
    "    for df in [merged_df, premium_df, coverage_df1, coverage_df2]:  \n",
    "        df.to_excel(writer, index=False, sheet_name='Insurance Report', startrow=last_row) \n",
    "        \n",
    "        \n",
    "\n",
    "        # Update last_row after writing each DataFrame  \n",
    "        last_row = worksheet.max_row + 2  \n",
    "\n",
    "        # Apply the same styling and formatting to each appended DataFrame  \n",
    "        for col in worksheet.iter_cols(min_row=last_row):  \n",
    "            if not col:  # If the column is empty, skip  \n",
    "                continue  \n",
    "            \n",
    "            max_length = 0  \n",
    "            column_letter = get_column_letter(col[0].column)\n",
    "        for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row, min_col=1, max_col=worksheet.max_column):\n",
    "            for cell in row:\n",
    "                cell.border = border\n",
    "    \n",
    "\n",
    "            for cell in col:  \n",
    "                if cell.value:  # Only check non-empty cells  \n",
    "                    max_length = max(max_length, len(str(cell.value)))  \n",
    "\n",
    "            adjusted_width = max(max_length + 2, min_width)  \n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width  \n",
    "\n",
    "            # Apply borders  \n",
    "            for cell in col:  \n",
    "                cell.border = border  \n",
    "\n",
    "    # Save changes  \n",
    "    workbook.save(excel_file)  \n",
    "\n",
    "print(f'Data successfully written to {excel_file}') \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e3f89d-4b9c-4fd9-9bda-3e73a39b0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Regex patterns for part 1\n",
    "amount_re = re.compile(r'([A-Za-z\\s,]+?)(?:\\s+\\$([\\d,]+\\.\\d{2})| Not Covered|:\\s*\\$.00)')\n",
    "total_re = re.compile(r'Estimated Total Premium:\\s*\\$([\\d,]+\\.\\d{2})')\n",
    "amount_re2 = re.compile(r'([A-Za-z\\s$$]+)\\s+\\$([\\d,]+(?:\\.\\d{2})?)')\n",
    "amount_re1 = re.compile(r'([A-Za-z\\s/()]+)\\s+(\\$\\d{1,3}(?:,\\d{3})*(?:/\\s*\\$?\\d{1,3}(?:,\\d{3})*)?)?\\s+(\\$\\d{1,3}(?:,\\d{3})*(?:/\\s*\\$?\\d{1,3}(?:,\\d{3})*)?)?\\s+(\\$\\d{1,3}(?:,\\d{3})*(?:/\\s*\\$?\\d{1,3}(?:,\\d{3})*)?)?(?:\\s+Included)?')\n",
    "total_re1 = re.compile(r'([A-Za-z\\s,]+?)(?:\\s+\\$([\\d,]+\\.\\d{2})(?:\\s+\\$([\\d,]+\\.\\d{2}))(?:\\s+\\$([\\d,]+\\.\\d{2})))')\n",
    "premium_pattern = re.compile(r'Premium by Vehicle\\s+(\\$[\\d,]+\\.\\d{2})\\s+(\\$[\\d,]+\\.\\d{2})\\s+(\\$[\\d,]+\\.\\d{2})')\n",
    "pattern = re.compile(r'^(.*?)\\s+\\$(.*?)\\s+(\\d+(?:,\\d+)?(?:\\.\\d+)?)\\s*(\\d+|$)', re.MULTILINE)  \n",
    "vehicle_premium_pattern = re.compile(r\"Total premium for \\d{4} [A-Z]+\\s*[A-Z]*\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\")  \n",
    "total_policy_premium_pattern = re.compile(r\"Total Policy Premium:\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\")  \n",
    "subtotal_policy_premium_pattern = re.compile(r\"Subtotal policy premium\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\")  \n",
    "total_6_month_premium_pattern = re.compile(r\"Total 6 month policy premium and fees\\s*\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\")  \n",
    "\n",
    "# Initialize lists to hold the extracted data for part 1\n",
    "\n",
    "lines_list1 = []\n",
    "lines_list2 = []\n",
    "lines_list3 = []\n",
    "premiums_first_pdf = []  \n",
    "premiums_second_pdf = []\n",
    "lines_list_first_pdf = []  \n",
    "lines_list_second_pdf = []\n",
    "Named_Insured_Mailing_Address = []  \n",
    "Policy_Number = []  \n",
    "Effective = []\n",
    "found_named_insured = False  \n",
    "found_policy_number = False  \n",
    "found_effective_from = False\n",
    "# Process the first PDF file for part 1\n",
    "with pdfplumber.open(files1[0]) as pdf:  \n",
    "    for page in pdf.pages:  \n",
    "        text = page.extract_text()  \n",
    "        if text:\n",
    "            \n",
    "            premium_match = premium_pattern.search(text)  \n",
    "            if premium_match:  \n",
    "                premium1 = premium_match.group(1)  \n",
    "                premium2 = premium_match.group(2)  \n",
    "                premium3 = premium_match.group(3)  \n",
    "                premiums_first_pdf.append((premium1, premium2, premium3))\n",
    "            lines = text.split('\\n')\n",
    "            for line in lines:\n",
    "                match = amount_re1.search(line)\n",
    "                match1 = total_re1.search(line)\n",
    "                if match:\n",
    "                    coverage = match.group(1).strip()  \n",
    "                    premium1 = match.group(2).strip() if match.group(2) else None  \n",
    "                    premium2 = match.group(3).strip() if match.group(3) else None  \n",
    "                    premium3 = match.group(4).strip() if match.group(4) else None  \n",
    "                    lines_list_first_pdf.append(CoverageDetails(Coverage=coverage, Premium1=premium1, Premium2=premium2, Premium3=premium3, Premium1_1=None, Premium2_1=None, Premium3_1=None))\n",
    "                elif match1:\n",
    "                    coverage = match1.group(1).strip()\n",
    "                    premium1 = match1.group(2).strip() if match1.group(2) else None\n",
    "                    premium2 = match1.group(3).strip() if match1.group(3) else None\n",
    "                    premium3 = match1.group(4).strip() if match1.group(4) else None\n",
    "                    lines_list_first_pdf.append(CoverageDetails(Coverage=coverage, Premium1=premium1, Premium2=premium2, Premium3=premium3, Premium1_1=None, Premium2_1=None, Premium3_1=None))\n",
    "            pre_index = [i + 1 for i, x in enumerate(lines) if \"Named Insured and Mailing Address:\" in x]  \n",
    "            pre_index1 = [i + 1 for i, x in enumerate(lines) if \"Named Insured:\" in x]  \n",
    "            pre_index2 = [i + 1 for i, x in enumerate(lines) if \"Drivers and household residents\" in x]\n",
    "            if pre_index:  \n",
    "                Named_Insured_Mailing_Address.append(lines[pre_index[0]])  \n",
    "                found_named_insured = True\n",
    "                # if found_named_insured:\n",
    "                #     break\n",
    "            elif pre_index1:  \n",
    "                Named_Insured_Mailing_Address.append(lines[pre_index1[0]])  \n",
    "                found_named_insured = True  \n",
    "            elif pre_index2:  \n",
    "                Named_Insured_Mailing_Address.append(lines[pre_index2[0]])  \n",
    "                found_named_insured = True\n",
    "\n",
    "            # Extract Policy Number\n",
    "            if not found_policy_number:  \n",
    "                pro_index = [i for i, x in enumerate(lines) if \"Policy Number:\" in x]\n",
    "                pro1_index = [i+1 for i, x in enumerate(lines) if \"Policy Number:\" in x]\n",
    "                if pro_index:\n",
    "                    if lines[pro_index[0]] != \"Policy Number:\":\n",
    "                        Policy_Number.append(lines[pro_index[0]])\n",
    "                        found_policy_number = True        \n",
    "                    else:\n",
    "                        Policy_Number.append(lines[pro1_index[0]])  \n",
    "                        found_policy_number = True\n",
    "            \n",
    "            # Extract Effective Dates\n",
    "            if not found_effective_from:  \n",
    "                pr_index = [i for i, x in enumerate(lines) if \"Policy Effective \" in x]  \n",
    "                pr_index1 = [i for i, x in enumerate(lines) if \"Policy Period:\" in x]  \n",
    "                if pr_index:  \n",
    "                    Effective.append(lines[pr_index[0]])  \n",
    "                    if pr_index[0] + 1 < len(lines):  \n",
    "                        Effective.append(lines[pr_index[0] + 1])  \n",
    "                    found_effective_from = True  \n",
    "                if pr_index1:  \n",
    "                    Effective.append(lines[pr_index1[0]])  \n",
    "                    if pr_index1[0] + 1 < len(lines):  \n",
    "                        Effective.append(lines[pr_index1[0] + 1])  \n",
    "                    found_effective_from = True\n",
    "            #print(\"Extracted text for PDF 1:\", lines)  # Debug print\n",
    "            \n",
    "            # Processing coverage parts\n",
    "            index = [i for i, x in enumerate(lines) if \"This policy consists of the following coverage parts: \" in x]\n",
    "            if index:\n",
    "                start_line = index[0] + 1\n",
    "                for line in lines[start_line:]:\n",
    "                    match2 = amount_re.search(line)\n",
    "                    if match2:\n",
    "                        coverage = match2.group(1).strip()\n",
    "                        premium = match2.group(2).strip() if match2.group(2) else \"Not Covered\"\n",
    "                        lines_list1.append(Line(Commercial_Package_Policy=coverage, Premium_Policy=premium, Premium_Policy1=\"\"))\n",
    "                        #print(f\"Matched coverage: {coverage}, premium: {premium}\")  # Debug print\n",
    "\n",
    "                    match3 = total_re.search(line)\n",
    "                    if match3:\n",
    "                        total_premium = match3.group(1).strip()\n",
    "                        lines_list1.append(Line(\"Estimated Total Premium\", total_premium, \"\"))\n",
    "            index1 = [i + 1 for i, x in enumerate(lines) if \"Primary use of the vehicle: Pleasure/Personal\" in x]\n",
    "            if index1:\n",
    "                start_line = index1[0]\n",
    "                for line in lines[start_line:]:\n",
    "                    match4 = pattern.match(line)\n",
    "                    vehicle_premium_match = vehicle_premium_pattern.search(line)\n",
    "                    total_policy_premium_match = total_policy_premium_pattern.search(line)\n",
    "                    subtotal_policy_premium_match = subtotal_policy_premium_pattern.search(line)\n",
    "                    total_6_month_premium_match = total_6_month_premium_pattern.search(line)\n",
    "                    \n",
    "                    if match4:\n",
    "                        coverage_title = match4.group(1).strip()\n",
    "                        limits = match4.group(2).strip()\n",
    "                        notes = match4.group(3).strip() if match4.group(3) is not None else \"\"\n",
    "                        lines_list2.append(Line1(Coverage_Type=coverage_title, Limit=limits, Premium=notes, Limit1=None, Premium1=None))\n",
    "\n",
    "                    if vehicle_premium_match:\n",
    "                        lines_list2.append(Line1(Coverage_Type=\"Vehicle Premium\", Limit=None, Premium=vehicle_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if total_policy_premium_match:\n",
    "                        lines_list2.append(Line1(Coverage_Type=\"Total Policy Premium\", Limit=None, Premium=total_policy_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if subtotal_policy_premium_match:\n",
    "                        lines_list2.append(Line1(Coverage_Type=\"Subtotal Policy Premium\", Limit=None, Premium=subtotal_policy_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if total_6_month_premium_match:\n",
    "                        lines_list2.append(Line1(Coverage_Type=\"Total 6 Month Premium\", Limit=None, Premium=total_6_month_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "                        #print(f\"Matched total premium: {total_premium}\")  # Debug print\n",
    "df1 = pd.DataFrame(lines_list2)\n",
    "           \n",
    "\n",
    "# Process the second PDF file and update Premium1 for part 1\n",
    "with pdfplumber.open(files1[1]) as pdf:  \n",
    "    for page in pdf.pages:  \n",
    "        text = page.extract_text()  \n",
    "        if text:\n",
    "            premium_match = premium_pattern.search(text)  \n",
    "            if premium_match:  \n",
    "                premium1_1 = premium_match.group(1)  \n",
    "                premium2_1 = premium_match.group(2)  \n",
    "                premium3_1 = premium_match.group(3)  \n",
    "                premiums_second_pdf.append((premium1_1, premium2_1, premium3_1))\n",
    "            lines = text.split('\\n')\n",
    "            for line in lines:\n",
    "                match = amount_re1.search(line)\n",
    "                match1 = total_re1.search(line)\n",
    "                if match:\n",
    "                    coverage = match.group(1).strip()  \n",
    "                    premium1 = match.group(2).strip() if match.group(2) else None  \n",
    "                    premium2 = match.group(3).strip() if match.group(3) else None  \n",
    "                    premium3 = match.group(4).strip() if match.group(4) else None  \n",
    "                    lines_list_second_pdf.append(CoverageDetails(Coverage=coverage, Premium1=premium1, Premium2=premium2, Premium3=premium3, Premium1_1=None, Premium2_1=None, Premium3_1=None))\n",
    "                elif match1:\n",
    "                    coverage = match1.group(1).strip()\n",
    "                    premium1 = match1.group(2).strip() if match1.group(2) else None\n",
    "                    premium2 = match1.group(3).strip() if match1.group(3) else None\n",
    "                    premium3 = match1.group(4).strip() if match1.group(4) else None\n",
    "                    lines_list_second_pdf.append(CoverageDetails(Coverage=coverage, Premium1=premium1, Premium2=premium2, Premium3=premium3, Premium1_1=None, Premium2_1=None, Premium3_1=None))\n",
    "            #print(\"Extracted text for PDF 2:\", lines)  # Debug print\n",
    "            \n",
    "\n",
    "            # Processing coverage parts\n",
    "            index = [i for i, x in enumerate(lines) if \"This policy consists of the following coverage parts: \" in x]\n",
    "            if index:\n",
    "                start_line = index[0] + 1\n",
    "                for i, line in enumerate(lines[start_line:]):\n",
    "                    match2 = amount_re.search(line)\n",
    "                    if match2 and i < len(lines_list1):  \n",
    "                        premium1 = match2.group(2).strip() if match2.group(2) else \"Not Covered\"\n",
    "                        lines_list1[i] = lines_list1[i]._replace(Premium_Policy1=premium1)  \n",
    "                        #print(f\"Updated line {i} with Premium_Policy1: {premium1}\")  # Debug print\n",
    "\n",
    "                    match3 = total_re.search(line)\n",
    "                    if match3 and i < len(lines_list1):  \n",
    "                        total_premium1 = match3.group(1).strip()\n",
    "                        if lines_list1[i].Commercial_Package_Policy == \"Estimated Total Premium\":\n",
    "                            lines_list1[i] = lines_list1[i]._replace(Premium_Policy1=total_premium1)\n",
    "            index2 = [i + 1 for i, x in enumerate(lines) if \"Primary use of the vehicle: Pleasure/Personal\" in x]\n",
    "            if index2:\n",
    "                start_line = index2[0]\n",
    "                for line in lines[start_line:]:\n",
    "                    match4 = pattern.match(line)\n",
    "                    vehicle_premium_match = vehicle_premium_pattern.search(line)\n",
    "                    total_policy_premium_match = total_policy_premium_pattern.search(line)\n",
    "                    subtotal_policy_premium_match = subtotal_policy_premium_pattern.search(line)\n",
    "                    total_6_month_premium_match = total_6_month_premium_pattern.search(line)\n",
    "                    \n",
    "                    if match3:\n",
    "                        coverage_title = match4.group(1).strip()\n",
    "                        limits = match4.group(2).strip()\n",
    "                        notes = match4.group(3).strip() if match4.group(3) is not None else \"\"\n",
    "                        lines_list3.append(Line1(Coverage_Type=coverage_title, Limit=limits, Premium=notes, Limit1=None, Premium1=None))\n",
    "\n",
    "                    if vehicle_premium_match:\n",
    "                        lines_list3.append(Line1(Coverage_Type=\"Vehicle Premium\", Limit=None, Premium=vehicle_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if total_policy_premium_match:\n",
    "                        lines_list3.append(Line1(Coverage_Type=\"Total Policy Premium\", Limit=None, Premium=total_policy_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if subtotal_policy_premium_match:\n",
    "                        lines_list3.append(Line1(Coverage_Type=\"Subtotal Policy Premium\", Limit=None, Premium=subtotal_policy_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "\n",
    "                    if total_6_month_premium_match:\n",
    "                        lines_list3.append(Line1(Coverage_Type=\"Total 6 Month Premium\", Limit=None, Premium=total_6_month_premium_match.group(1).strip(), Limit1=None, Premium1=None))\n",
    "                            #print(f\"Updated total premium for Estimated Total Premium: {total_premium1}\")  # Debug print\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(lines_list3)            \n",
    "               \n",
    "# Convert to DataFrame for part 1\n",
    "coverage_df1 = pd.DataFrame(lines_list1)\n",
    "df = pd.DataFrame(lines_list2)\n",
    "# Verify DataFrame columns and data\n",
    "# print(\"DataFrame for part 1:\", coverage_df1)\n",
    "\n",
    "# Check if DataFrame is empty\n",
    "if coverage_df1.empty:\n",
    "    print(\"No data was collected for coverage_df1.\")\n",
    "else:\n",
    "    # Handle empty strings and non-numeric values in 'Premium' and 'Premium1' for part 1\n",
    "    coverage_df1['Premium_Policy'] = coverage_df1['Premium_Policy'].replace(['Not Covered', ''], '0').str.replace(',', '').astype(float)\n",
    "    coverage_df1['Premium_Policy1'] = coverage_df1['Premium_Policy1'].replace(['Not Covered', ''], '0').str.replace(',', '').astype(float)\n",
    "\n",
    "    # Add a new column 'Difference' by subtracting Premium1 from Premium for part 1\n",
    "    coverage_df1['Difference'] = coverage_df1['Premium_Policy'] - coverage_df1['Premium_Policy1']\n",
    "coverage_df2 = pd.DataFrame(lines_list_first_pdf)\n",
    "\n",
    "# Verify DataFrame columns for coverage_df2\n",
    "# print(\"DataFrame columns for part 2:\", coverage_df2.columns)\n",
    "\n",
    "# Match and update the DataFrame with data from the second PDF for part 2\n",
    "for entry2 in lines_list_second_pdf:\n",
    "    matched = False\n",
    "    for i, row in coverage_df2.iterrows():\n",
    "        if row['Coverage'] == entry2.Coverage:\n",
    "            coverage_df2.at[i, 'Premium1_1'] = entry2.Premium1\n",
    "            coverage_df2.at[i, 'Premium2_1'] = entry2.Premium2\n",
    "            coverage_df2.at[i, 'Premium3_1'] = entry2.Premium3\n",
    "            matched = True\n",
    "            break\n",
    "    if not matched:\n",
    "        print(f\"Coverage '{entry2.Coverage}' from second PDF did not match any entry in the first PDF.\")\n",
    "\n",
    "# Add columns for differences for part 2\n",
    "coverage_df2['difference1_1'] = None\n",
    "coverage_df2['difference2_1'] = None\n",
    "coverage_df2['difference3_1'] = None\n",
    "\n",
    "# Calculate differences for part 2\n",
    "for i, row in coverage_df2.iterrows():\n",
    "    def parse_premium(premium_str):\n",
    "        if premium_str is None:\n",
    "            return None\n",
    "        numeric_parts = re.findall(r'\\d+(?:,\\d{3})*(?:\\.\\d{2})?', premium_str)\n",
    "        if numeric_parts:\n",
    "            return float(numeric_parts[0].replace(',', ''))\n",
    "        return None\n",
    "\n",
    "    premium1 = parse_premium(row['Premium1'])\n",
    "    premium1_1 = parse_premium(row['Premium1_1'])\n",
    "    premium2 = parse_premium(row['Premium2'])\n",
    "    premium2_1 = parse_premium(row['Premium2_1'])\n",
    "    premium3 = parse_premium(row['Premium3'])\n",
    "    premium3_1 = parse_premium(row['Premium3_1'])\n",
    "    \n",
    "    coverage_df2.at[i, 'difference1_1'] = (premium1_1 - premium1) if premium1 is not None and premium1_1 is not None else None\n",
    "    coverage_df2.at[i, 'difference2_1'] = (premium2_1 - premium2) if premium2 is not None and premium2_1 is not None else None\n",
    "    coverage_df2.at[i, 'difference3_1'] = (premium3_1 - premium3) if premium3 is not None and premium3_1 is not None else None\n",
    "\n",
    "# Display the updated DataFrames\n",
    "\n",
    "print(\"Coverage DataFrame from part 1:\")\n",
    "print(coverage_df1)\n",
    "print(\"\\nCoverage DataFrame from part 2:\")\n",
    "print(coverage_df2)\n",
    "\n",
    "min_length = min(len(premiums_first_pdf), len(premiums_second_pdf))  \n",
    "# print(f\"Minimum length of premiums: {min_length}\")  # Debug print  \n",
    "\n",
    "premiums_first_pdf = premiums_first_pdf[:min_length]  \n",
    "premiums_second_pdf = premiums_second_pdf[:min_length]  \n",
    "\n",
    "# Create PremiumDetails instances  \n",
    "premium_details_list = [  \n",
    "    PremiumDetails(  \n",
    "        Premium_Coverage=\"Premium of Vehicles\",  \n",
    "        Premium1=premiums_first_pdf[i][0],  \n",
    "        Premium2=premiums_first_pdf[i][1],  \n",
    "        Premium3=premiums_first_pdf[i][2],  \n",
    "        Premium1_1=premiums_second_pdf[i][0],  \n",
    "        Premium2_1=premiums_second_pdf[i][1],  \n",
    "        Premium3_1=premiums_second_pdf[i][2]  \n",
    "    )  \n",
    "    for i in range(min_length)  \n",
    "]  \n",
    "\n",
    "# Check if the premium details are populated  \n",
    "# print(\"Premium details list:\", premium_details_list)  \n",
    "\n",
    "# Create a DataFrame from the list of PremiumDetails  \n",
    "premium_df = pd.DataFrame(premium_details_list)  \n",
    "\n",
    "# Verify the DataFrame structure  \n",
    "# print(\"DataFrame structure:\\n\", premium_df.head())  \n",
    "\n",
    "# Convert premium columns to numeric values, if they exist  \n",
    "premium_columns = ['Premium1', 'Premium2', 'Premium3', 'Premium1_1', 'Premium2_1', 'Premium3_1']  \n",
    "for col in premium_columns:  \n",
    "    if col in premium_df.columns:  # Check if the column exists  \n",
    "        premium_df[col] = premium_df[col].replace({'\\$': '', ',': ''}, regex=True).astype(float)  \n",
    "    else:  \n",
    "        print(f\"Warning: Column {col} not found in the DataFrame.\")  \n",
    "\n",
    "# Proceed if DataFrame has required columns  \n",
    "if len(premium_df.columns) > 0:  \n",
    "    # Add TotalPremium1 and TotalPremium2 columns  \n",
    "    premium_df['TotalPremium1'] = premium_df[['Premium1', 'Premium2', 'Premium3']].sum(axis=1)  \n",
    "    premium_df['TotalPremium2'] = premium_df[['Premium1_1', 'Premium2_1', 'Premium3_1']].sum(axis=1)  \n",
    "\n",
    "    # Add Difference column  \n",
    "    premium_df['Difference'] = premium_df['TotalPremium1'] - premium_df['TotalPremium2']  \n",
    "\n",
    "    # Print the final DataFrame  \n",
    "    print(premium_df)  \n",
    "else:  \n",
    "    print(\"No valid premium data found. DataFrame is empty.\")   \n",
    "print(\"Columns in df1:\", df1.columns.tolist())  \n",
    "print(\"Columns in df2:\", df2.columns.tolist())\n",
    "print(\"DF1 contents:\\n\", df1.head())\n",
    "print(\"DF2 contents:\\n\", df2.head())\n",
    "\n",
    "# Check if 'Coverage_Type' is in both dataframes\n",
    "if 'Coverage_Type' not in df1.columns:\n",
    "    print(\"Coverage_Type column not found in df1\")\n",
    "\n",
    "if 'Coverage_Type' not in df2.columns:\n",
    "    print(\"Coverage_Type column not found in df2\")\n",
    "\n",
    "# Merge data from the two PDFs\n",
    "merged_df = df1.copy()\n",
    "\n",
    "# Update 'Limit1' and 'Premium1' columns from df2\n",
    "for index, row in merged_df.iterrows():\n",
    "    corresponding_row = df2[df2['Coverage_Type'] == row['Coverage_Type']]\n",
    "    if not corresponding_row.empty:\n",
    "        merged_df.at[index, 'Limit1'] = corresponding_row['Limit'].values[0]\n",
    "        merged_df.at[index, 'Premium1'] = corresponding_row['Premium'].values[0]\n",
    "\n",
    "# Check merged DataFrame structure\n",
    "print(\"Merged DataFrame structure before cleaning:\\n\", merged_df.head())\n",
    "print(\"Merged DataFrame columns:\\n\", merged_df.columns.tolist()) \n",
    "\n",
    "# Function to clean and convert currency strings to floats\n",
    "def clean_currency(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace(',', '').replace('$', '')\n",
    "        try:\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return float(value) if value else None\n",
    "\n",
    "# Apply the cleaning function to Premium and Premium1 columns\n",
    "if 'Premium' in merged_df.columns and 'Premium1' in merged_df.columns:\n",
    "    merged_df['Premium'] = merged_df['Premium'].apply(clean_currency)\n",
    "    merged_df['Premium1'] = merged_df['Premium1'].apply(clean_currency)\n",
    "    conditions = merged_df['Coverage_Type'].isin([\"Vehicle Premium\", \"Subtotal Policy Premium\", \"Total 6 Month Premium\"])\n",
    "    merged_df.loc[conditions, 'Difference'] = merged_df['Premium1'] - merged_df['Premium']\n",
    "else:\n",
    "    print(\"Necessary columns are missing in the merged DataFrame.\")\n",
    "# max_length = max(len(Named_Insured_Mailing_Address), len(Policy_Number), len(Effective))\n",
    "\n",
    "# Extend the lists to match the maximum length\n",
    "Named_Insured_Mailing_Address.extend([None] * (max_length - len(Named_Insured_Mailing_Address)))\n",
    "Policy_Number.extend([None] * (max_length - len(Policy_Number)))\n",
    "Effective.extend([None] * (max_length - len(Effective)))\n",
    "\n",
    "# Create the DataFrame\n",
    "policy_data = pd.DataFrame({\n",
    "    'Named Insured': Named_Insured_Mailing_Address,\n",
    "    \"Policy Number\": Policy_Number,\n",
    "    \"Effective\": Effective,\n",
    "}).drop_duplicates()\n",
    "print(\"Policy_data\")\n",
    "print(policy_data)\n",
    "\n",
    "\n",
    "# Print the merged DataFrame to see the extracted information with the calculated differences\n",
    "print('merged_df')\n",
    "print(merged_df)\n",
    "excel_file = 'insurance_report_combined.xlsx'  \n",
    "with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:  \n",
    "    policy_data.to_excel(writer, index=False, sheet_name='Insurance Report', startrow=2)  \n",
    "    \n",
    "    # Access the workbook and the worksheet  \n",
    "    workbook = writer.book  \n",
    "    worksheet = writer.sheets['Insurance Report']  \n",
    "\n",
    "    # Add headings for the policy report  \n",
    "    report_heading = \"Insurance Report\"  \n",
    "    worksheet.merge_cells('A1:C1')  \n",
    "    cell = worksheet.cell(row=1, column=1)  \n",
    "    cell.value = report_heading  \n",
    "    cell.alignment = Alignment(horizontal='center', vertical='center')  \n",
    "    cell.font = Font(bold=True)  \n",
    "\n",
    "    # Add border style for the columns  \n",
    "    border = Border(left=Side(style='thin'), right=Side(style='thin'), top=Side(style='thin'), bottom=Side(style='thin'))  \n",
    "    \n",
    "    min_width = 20  # Minimum column width  \n",
    "\n",
    "    # Set column widths and apply styles  \n",
    "    for col in worksheet.columns:  \n",
    "        if not col:  # If the column is empty, skip  \n",
    "            continue  \n",
    "        \n",
    "        max_length = 0  \n",
    "        column_letter = get_column_letter(col[0].column)  \n",
    "\n",
    "        for cell in col:  \n",
    "            if cell.value:  # Check if the cell is not empty  \n",
    "                max_length = max(max_length, len(str(cell.value)))  # Update max_length  \n",
    "            \n",
    "        adjusted_width = max(max_length + 2, min_width)  # Add some extra space  \n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "        # Set borders for each cell in the column  \n",
    "        for cell in col:  \n",
    "            cell.border = border  \n",
    "\n",
    "    # Make header row bold (now it’s row 3 after writing the policy data)  \n",
    "    for cell in worksheet[2]:  # Row indexing starts from 1  \n",
    "        cell.font = Font(bold=True)  # Make the header bold  \n",
    "\n",
    "    # Loop to append additional DataFrames   \n",
    "    last_row = worksheet.max_row + 2  \n",
    "    for df in [merged_df, premium_df, coverage_df1, coverage_df2]:  \n",
    "        df.to_excel(writer, index=False, sheet_name='Insurance Report', startrow=last_row) \n",
    "        \n",
    "        \n",
    "\n",
    "        # Update last_row after writing each DataFrame  \n",
    "        last_row = worksheet.max_row + 2  \n",
    "\n",
    "        # Apply the same styling and formatting to each appended DataFrame  \n",
    "        for col in worksheet.iter_cols(min_row=last_row):  \n",
    "            if not col:  # If the column is empty, skip  \n",
    "                continue  \n",
    "            \n",
    "            max_length = 0  \n",
    "            column_letter = get_column_letter(col[0].column)\n",
    "        for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row, min_col=1, max_col=worksheet.max_column):\n",
    "            for cell in row:\n",
    "                cell.border = border\n",
    "    \n",
    "\n",
    "            for cell in col:  \n",
    "                if cell.value:  # Only check non-empty cells  \n",
    "                    max_length = max(max_length, len(str(cell.value)))  \n",
    "\n",
    "            adjusted_width = max(max_length + 2, min_width)  \n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width  \n",
    "\n",
    "            # Apply borders  \n",
    "            for cell in col:  \n",
    "                cell.border = border  \n",
    "\n",
    "    # Save changes  \n",
    "    workbook.save(excel_file)  \n",
    "\n",
    "print(f'Data successfully written to {excel_file}') \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded273c-964d-4ba3-9f9b-a254b6212bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
